<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Alex Banks!</title><link>https://abankspdx.github.io/</link><description>Recent content on Alex Banks!</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sun, 22 Jan 2023 16:23:50 -0800</lastBuildDate><atom:link href="https://abankspdx.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>Trie</title><link>https://abankspdx.github.io/posts/trie/</link><pubDate>Sun, 22 Jan 2023 16:23:50 -0800</pubDate><guid>https://abankspdx.github.io/posts/trie/</guid><description>Tries, the Word Search Data Structure! A bunch of years ago I learned about Tries. I thought they were pretty nifty! Today I decided to write about them.
What&amp;rsquo;s a trie? In essence, a Trie is a data structure comprized of a bunch of nested Maps/Dictionaries. So, if you enter &amp;ldquo;alex&amp;rdquo; into a Trie, your internal structure looks like this:
{ &amp;#34;a&amp;#34;: { &amp;#34;l&amp;#34;: { &amp;#34;e&amp;#34;: { &amp;#34;x&amp;#34;: {} } } } } To better demonstrate, if we added &amp;ldquo;alan&amp;rdquo; to that same Trie, the underlying data structure would look like:</description></item><item><title>Python Codat Sync</title><link>https://abankspdx.github.io/posts/python-codat-sync/</link><pubDate>Tue, 17 Jan 2023 22:57:09 -0800</pubDate><guid>https://abankspdx.github.io/posts/python-codat-sync/</guid><description>Python Scripting! Recently I was tasked with writing a quick sync script to pull data from Codat (https://www.codat.io/). I haven&amp;rsquo;t written the output yet (currently just JSON), but for the purposes of this post I thought my impl was good enough. I also omitted things like error notifications and remote logging (to be implemented later) - I kind of just wanted to get some thoughts out there with regard to structuring a script that syncs the contents of an external REST API.</description></item><item><title>About Me</title><link>https://abankspdx.github.io/about/</link><pubDate>Wed, 04 Jan 2023 16:13:31 -0800</pubDate><guid>https://abankspdx.github.io/about/</guid><description>Hello! My name is Alex Banks. I&amp;rsquo;m a software and data engineer in Portland Oregon! I&amp;rsquo;ve been working in software for about 10 years (but programming since ~2001) with a passion for data, analytics and cloud technology.
Currently I&amp;rsquo;ve worked as a Lead Data Engineer at FlowFi, a accounting and virtual CFO firm helping startups manage their money. Prior to that I worked in game analytics at Kongregate, and as a data/cloud engineer for wind energy.</description></item><item><title>Druid Kubernetes Pain</title><link>https://abankspdx.github.io/posts/druid-kubernetes-pain/</link><pubDate>Wed, 04 Jan 2023 04:09:44 -0800</pubDate><guid>https://abankspdx.github.io/posts/druid-kubernetes-pain/</guid><description>Druid? Yes. Kubernetes? Maybe. Networking? Scary. I got the bright idea to try and deploy an Apache Druid (https://druid.apache.org/) cluster to Kubernetes recently. I&amp;rsquo;ve never worked with either technology so I thought it&amp;rsquo;d be fun.
I was wrong.
Druid Druid seems great. Understanding the overall model of the software was pretty straightforward. There are a couple node types that each serve a specific purpose in the cluster, some of which being stateful (obviously, it&amp;rsquo;s a database).</description></item><item><title>Fivetran Dbt Adventure</title><link>https://abankspdx.github.io/posts/fivetran-dbt-adventure/</link><pubDate>Mon, 02 Jan 2023 16:26:48 -0800</pubDate><guid>https://abankspdx.github.io/posts/fivetran-dbt-adventure/</guid><description>A real adventure Recently I&amp;rsquo;ve been working on converting our custom (and costly) ETL system into a more standardized (and cost effective) ELT system using Fivetran. Fivetran seems great (https://www.fivetran.com) for ingesting variable amounts of data on regular intervals. I&amp;rsquo;m using it right now to ingest Quickbooks, Shopify, Klaviyo and Plaid data into our Snowflake data warehouse. A problem that I did not envision was Fivetran requiring every connector (something that pulls from a Source and writes to a Destination) to require its own database schema in Snowflake.</description></item></channel></rss>