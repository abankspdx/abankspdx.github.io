<!doctype html><html class="not-ready text-sm lg:text-base" style=--bg:#faf6f1 lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><title>Fivetran Dbt Adventure - Alex Banks!</title><meta name=theme-color><meta name=description content="A real adventure Recently I&rsquo;ve been working on converting our custom (and costly) ETL system into a more standardized (and cost effective) ELT system using Fivetran. Fivetran seems great (https://www.fivetran.com) for ingesting variable amounts of data on regular intervals. I&rsquo;m using it right now to ingest Quickbooks, Shopify, Klaviyo and Plaid data into our Snowflake data warehouse. A problem that I did not envision was Fivetran requiring every connector (something that pulls from a Source and writes to a Destination) to require its own database schema in Snowflake."><meta name=author content><link rel="preload stylesheet" as=style href=https://abankspdx.github.io/main.min.css><script defer src=https://abankspdx.github.io/highlight.min.js onload=hljs.initHighlightingOnLoad()></script>
<link rel=preload as=image href=https://abankspdx.github.io/theme.png><link rel=icon href=https://abankspdx.github.io/favicon.ico><link rel=apple-touch-icon href=https://abankspdx.github.io/apple-touch-icon.png><meta name=generator content="Hugo 0.110.0"><meta property="og:title" content="Fivetran Dbt Adventure"><meta property="og:description" content="A real adventure Recently I&rsquo;ve been working on converting our custom (and costly) ETL system into a more standardized (and cost effective) ELT system using Fivetran. Fivetran seems great (https://www.fivetran.com) for ingesting variable amounts of data on regular intervals. I&rsquo;m using it right now to ingest Quickbooks, Shopify, Klaviyo and Plaid data into our Snowflake data warehouse. A problem that I did not envision was Fivetran requiring every connector (something that pulls from a Source and writes to a Destination) to require its own database schema in Snowflake."><meta property="og:type" content="article"><meta property="og:url" content="https://abankspdx.github.io/posts/fivetran-dbt-adventure/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-01-02T16:26:48-08:00"><meta property="article:modified_time" content="2023-01-02T16:26:48-08:00"><meta itemprop=name content="Fivetran Dbt Adventure"><meta itemprop=description content="A real adventure Recently I&rsquo;ve been working on converting our custom (and costly) ETL system into a more standardized (and cost effective) ELT system using Fivetran. Fivetran seems great (https://www.fivetran.com) for ingesting variable amounts of data on regular intervals. I&rsquo;m using it right now to ingest Quickbooks, Shopify, Klaviyo and Plaid data into our Snowflake data warehouse. A problem that I did not envision was Fivetran requiring every connector (something that pulls from a Source and writes to a Destination) to require its own database schema in Snowflake."><meta itemprop=datePublished content="2023-01-02T16:26:48-08:00"><meta itemprop=dateModified content="2023-01-02T16:26:48-08:00"><meta itemprop=wordCount content="997"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="Fivetran Dbt Adventure"><meta name=twitter:description content="A real adventure Recently I&rsquo;ve been working on converting our custom (and costly) ETL system into a more standardized (and cost effective) ELT system using Fivetran. Fivetran seems great (https://www.fivetran.com) for ingesting variable amounts of data on regular intervals. I&rsquo;m using it right now to ingest Quickbooks, Shopify, Klaviyo and Plaid data into our Snowflake data warehouse. A problem that I did not envision was Fivetran requiring every connector (something that pulls from a Source and writes to a Destination) to require its own database schema in Snowflake."></head><body class="text-black duration-200 ease-out dark:text-white"><header class="mx-auto flex h-[5rem] max-w-3xl px-8 lg:justify-center"><div class="relative z-50 mr-auto flex items-center"><a class="-translate-x-[1px] -translate-y-0.5 text-3xl font-bold" href=https://abankspdx.github.io>Alex Banks!</a>
<a class="btn-dark ml-6 h-6 w-6 shrink-0 cursor-pointer [background:url(./theme.png)_left_center/_auto_theme('spacing.6')_no-repeat] [transition:_background-position_0.4s_steps(5)] dark:[background-position:right]"></a></div><a class="btn-menu relative z-50 -mr-8 flex h-[5rem] w-[5rem] shrink-0 cursor-pointer flex-col items-center justify-center gap-2.5 lg:hidden"></a>
<script>const htmlClass=document.documentElement.classList;setTimeout(()=>{htmlClass.remove("not-ready")},10);const btnMenu=document.querySelector(".btn-menu");btnMenu.addEventListener("click",()=>{htmlClass.toggle("open")});const metaTheme=document.querySelector('meta[name="theme-color"]'),lightBg=`"#faf6f1"`.replace(/"/g,""),setDark=e=>{metaTheme.setAttribute("content",e?"#000":lightBg),htmlClass[e?"add":"remove"]("dark"),localStorage.setItem("dark",e)},darkScheme=window.matchMedia("(prefers-color-scheme: dark)");if(htmlClass.contains("dark"))setDark(!0);else{const e=localStorage.getItem("dark");setDark(e?e==="true":darkScheme.matches)}darkScheme.addEventListener("change",e=>{setDark(e.matches)});const btnDark=document.querySelector(".btn-dark");btnDark.addEventListener("click",()=>{setDark(localStorage.getItem("dark")!=="true")})</script><div class="nav-wrapper fixed inset-x-0 top-full z-40 flex h-full select-none flex-col justify-center pb-16 duration-200 dark:bg-black lg:static lg:h-auto lg:flex-row lg:!bg-transparent lg:pb-0 lg:transition-none"><nav class="lg:ml-12 lg:flex lg:flex-row lg:items-center lg:space-x-6"><a class="block text-center text-2xl leading-[5rem] lg:text-base lg:font-normal" href=/about>About</a></nav></div></header><main class="prose prose-neutral relative mx-auto min-h-[calc(100%-10rem)] max-w-3xl px-8 pt-20 pb-32 dark:prose-invert"><article><header class=mb-20><h1 class="!my-0 pb-2.5">Fivetran Dbt Adventure</h1><div class="text-sm opacity-60"><time>Jan 2, 2023</time></div></header><section><h2 id=a-real-adventure>A real adventure</h2><p>Recently I&rsquo;ve been working on converting our custom (and costly) ETL system into a more standardized (and cost effective) ELT system using Fivetran. Fivetran seems great (<a href=https://www.fivetran.com>https://www.fivetran.com</a>) for ingesting variable amounts of data on regular intervals. I&rsquo;m using it right now to ingest Quickbooks, Shopify, Klaviyo and Plaid data into our Snowflake data warehouse. A problem that I did not envision was Fivetran requiring every connector (something that pulls from a Source and writes to a Destination) to require its own database schema in Snowflake. As in, because we have both a regular Quickbooks connector and a <em>custom</em> Quickbooks connector (because the out of the box connector <em>doesn&rsquo;t</em> ingest Quickbooks Reports), it will write them each to their own schema. For most people this is fine, but my goal is to reduce complexity as much as I can downstream, which means having to keep track of many schemas even for simple queries just doesn&rsquo;t cut it.</p><p>Enter Dbt.</p><h2 id=a-wild-wild-time>A wild, wild time</h2><p>Dbt stands for <code>Data Build Tool</code>. I don&rsquo;t know the history, but I sense a callback to Sbt, or <code>Scala Build Tool</code>. It&rsquo;s not clear to me how they&rsquo;re related but I didn&rsquo;t let that stop me. As I said, we&rsquo;re trying to take many schemas and many tables and consolidate them into a single schema and many tables. So, an example:</p><pre tabindex=0><code>quickbooks_2980823978490234.invoices =&gt; quickbooks.invoices
quickbooks_8293923732987329.invoices =&gt; quickbooks.invoices
</code></pre><p>Dbt works quite well for this style of work because each transformation is written to the database as a View, which means I don&rsquo;t have to worry about stale data.</p><h3 id=problem-1-relevant-schemas>Problem 1: Relevant schemas</h3><p>The first problem I could identify was figuring out what schemas in the warehouse even qualified for consolidation. An easy problem, but it was kind of the keystone behind all the upcoming problems. After playing around with some queries to test, I ended up making a table and a macro to solve this problem for me.</p><p><code>quickbooks.schema_tables</code>:</p><pre tabindex=0><code>SELECT table_schema
       , table_name 
FROM information_schema.tables 
WHERE table_schema like &#39;quickbooks_%&#39; 
AND table_schema not like &#39;%reports%&#39;
AND table_schema not like &#39;%inactive%&#39;
</code></pre><p><code>get_schemas_for_table_type</code>:</p><pre tabindex=0><code>{% macro get_schemas_for_table_type(table_type) %}
    select table_schema as schema_name from quickbooks.schema_tables where table_name = &#39;{{table_type}}&#39;
{% endmacro %}
</code></pre><p>Now, if I wanted to get relevant schemas for the <code>accounts</code> table type, I could call <code>get_schemas_for_table_type(accounts)</code> from a Dbt model and have all I needed.</p><h3 id=problem-2-columns>Problem 2: Columns</h3><p>Fivetran is great about schemas, in that it maintains and enforces schemas out of the box for official Fivetran connectors, but a real painpoint is that, if data doesn&rsquo;t exist for a certain field in a Fivetran source, it won&rsquo;t write empty columns to your destination (until data does start existing in that field). What this means is that you cannot simply <code>UNION ALL</code> across all qualifying tables, because some tables won&rsquo;t necessarily have all the same columns as the others (even if they&rsquo;re technically the same table type and schema).</p><p>To solve this, I (yet again) made a Dbt macro to grab shared columns for a table type.</p><pre tabindex=0><code>{% macro get_columns_for_table(table_name) %}
    {% set schemas_list_proxy = run_query(get_schemas_for_table_type(table_name)) %}
    {% if execute %}
        {% set schemas_list = schemas_list_proxy.columns[0].values() %}
    {% else %}
        {% set schemas_list = [] %}
    {% endif %}

    {% for schem in schemas_list %}
        {% if loop.first %} WITH {% endif %}
        {{schem}} as (
            SELECT column_name
            FROM information_schema.columns
            WHERE table_schema = &#39;{{schem}}&#39;
            AND table_name = &#39;{{table_name}}&#39;
            AND data_type NOT IN (&#39;json&#39;, &#39;jsonb&#39;)
        )
        {% if not loop.last %},{% endif %}
    {% endfor %}
    {% for schem in schemas_list %}
        SELECT column_name
        FROM {{schem}}
        {% if not loop.last %} INTERSECT {% endif %}
    {% endfor %}
{% endmacro %}
</code></pre><p>Essentially, this block is creating a list of relevant schemas, and then grabbing all common columns from each of those schemas.</p><h3 id=putting-it-together>Putting it together</h3><p>This part&rsquo;s kind of messy, but:</p><pre tabindex=0><code>    {% set cols_list_proxy = run_query(get_columns_for_table(table_name)) %}
    {% if execute %}
        {% set cols_list = cols_list_proxy.columns[0].values() %}
    {% else %}
        {% set cols_list = [] %}
    {% endif %}

    {% set schemas_list_proxy = run_query(get_schemas_for_table_type(table_name)) %}
    {% if execute %}
        {% set schemas_list = schemas_list_proxy.columns[0].values() %}
    {% else %}
        {% set schemas_list = [] %}
    {% endif %}

    with connection_info as (
        SELECT company_id, connection_id, id_slug
        FROM fivetran_schemas.connections
        WHERE institution_type = &#39;QUICKBOOKS&#39;
    ),

    {% for schema_name in schemas_list %}
        {{schema_name}} AS (
            select 
                ci.company_id,
                ci.connection_id,
                {{company_identifier(schema_name)}} as id_slug,
            {% for col in cols_list %}
                {{col}} {% if not loop.last %},{% endif %}
            {% endfor %}
            from {{schema_name}}.{{table_name}}
            inner join connection_info ci
            on ci.id_slug = id_slug
            where id_slug = {{company_identifier(schema_name)}}
        )
        {% if not loop.last %} , {% endif %}
    {% endfor %}
    {% for schema_name in schemas_list %}
        select *
        from {{schema_name}}
        {% if not loop.last %} union {% endif %}
    {% endfor %}
{% endmacro %}
</code></pre><p>Yet another macro that, when supplied a table type, gets all relevant schemas + all revenant columns and then does a massive <code>UNION</code> query against that data to create one big View, but with customer ID as a field in the resultset.
This, then, satisfies my original goal of merging all the <code>invoice</code> (this type just as an example) tables into a single <code>quickbooks.invoice</code> table.</p><p>To actually invoke the macro I wrote a simple script that grabbed every table type from the warehouse and wrote out an individual Dbt model for that type, into the <code>models</code> directory of my Dbt app. So then, I ended up with ~60 files that look like this:</p><pre tabindex=0><code>{{ consolidate_schemas(&#39;account&#39;) }}
</code></pre><p>Pretty simple!</p><h2 id=closing-thoughts>Closing thoughts</h2><p>This solution has some issues. If a new company gets added, the Dbt models must be recompiled to include that company&rsquo;s data in the view. Also, if an existing company gets a new field (because data got updated), we must also rerun the View. To solve this problem I run Dbt as a callback in a bunch of areas of our application, like company registration as an example, to be sure new companies get added with haste.</p><p>Overall I enjoyed working with Dbt and will continue to do so!</p></section><nav class="mt-24 flex rounded-lg bg-black/[3%] p-1.5 text-lg dark:bg-white/[8%]"><a class="flex w-1/2 items-center rounded-md p-6 pr-3 no-underline hover:bg-black/[2%]" href=https://abankspdx.github.io/posts/druid-kubernetes-pain/><span class=mr-1.5>←</span><span>Druid Kubernetes Pain</span></a></nav></article></main><footer class="opaco mx-auto flex h-[5rem] max-w-3xl items-center px-8 text-[0.9em] opacity-60"><div class=mr-auto>&copy; 2023
<a class=link href=https://abankspdx.github.io>Alex Banks!</a></div><a class="link mx-6" href=https://gohugo.io/ rel=noopener target=_blank>Powered by Hugo️️</a>️
<a class=link href=https://github.com/nanxiaobei/hugo-paper rel=noopener target=_blank>▷ Paper 6</a></footer></body></html>